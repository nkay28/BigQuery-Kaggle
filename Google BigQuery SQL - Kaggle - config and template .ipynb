{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c01327d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49527d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## REF: https://www.kaggle.com/code/dansbecker/getting-started-with-sql-and-bigquery \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfd95de",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.kaggle.com/code/beerus/exercise-getting-started-with-sql-and-bigquery/edit \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89c44b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c0b94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from google.cloud import bigquery\n",
    "\n",
    "# Create a \"Client\" object\n",
    "client = bigquery.Client()\n",
    "\n",
    "# Construct a reference to the \"openaq\" dataset\n",
    "dataset_ref = client.dataset(\"openaq\", project=\"bigquery-public-data\")\n",
    "\n",
    "# API request - fetch the dataset\n",
    "dataset = client.get_dataset(dataset_ref)\n",
    "\n",
    "# Construct a reference to the \"global_air_quality\" table\n",
    "table_ref = dataset_ref.table(\"global_air_quality\")\n",
    "\n",
    "# API request - fetch the table\n",
    "table = client.get_table(table_ref)\n",
    "\n",
    "# Preview the first five lines of the \"global_air_quality\" table\n",
    "client.list_rows(table, max_results=5).to_dataframe()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9413f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# list of tables in the dataset: \n",
    "tables = list(client.list_tables(dataset))\n",
    "\n",
    "for itm in tables:\n",
    "    #* \"table_id\" \n",
    "    print(itm.table_id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8386d70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query to select countries with units of \"ppm\"\n",
    "first_query = \"\"\"\n",
    "SELECT country \n",
    "FROM `bigquery-public-data.openaq.global_air_quality`\n",
    "WHERE unit = 'ppm'\n",
    "\"\"\" # Your code goes here\n",
    "\n",
    "# Set up the query (cancel the query if it would use too much of \n",
    "# your quota, with the limit set to 10 GB)\n",
    "safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\n",
    "first_query_job = client.query(first_query, job_config=safe_config)\n",
    "\n",
    "# API request - run the query, and return a pandas DataFrame\n",
    "first_results = first_query_job.to_dataframe()\n",
    "\n",
    "# View top few rows of results\n",
    "print(first_results.head())\n",
    "\n",
    "# Check your answer\n",
    "q_1.check()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d77f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here\n",
    "country_spend_pct_query = \"\"\"\n",
    "                          SELECT country_name, AVG(value) AS avg_ed_spending_pct \n",
    "                          FROM `bigquery-public-data.world_bank_intl_education.international_education`\n",
    "                          WHERE indicator_code = 'SE.XPD.TOTL.GD.ZS' AND year <= 2017 AND year >= 2010\n",
    "                          GROUP BY country_name\n",
    "                          ORDER BY avg_ed_spending_pct DESC\n",
    "                          \"\"\"\n",
    "\n",
    "# Set up the query (cancel the query if it would use too much of \n",
    "# your quota, with the limit set to 1 GB)\n",
    "safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\n",
    "country_spend_pct_query_job = client.query(country_spend_pct_query, job_config=safe_config)\n",
    "\n",
    "# API request - run the query, and return a pandas DataFrame\n",
    "country_spending_results = country_spend_pct_query_job.to_dataframe()\n",
    "\n",
    "# View top few rows of results\n",
    "print(country_spending_results.head())\n",
    "\n",
    "# Check your answer\n",
    "q_1.check()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4ca2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here\n",
    "code_count_query = \"\"\"\n",
    "SELECT indicator_code, indicator_name, COUNT(1) AS num_rows    \n",
    "FROM `bigquery-public-data.world_bank_intl_education.international_education`\n",
    "WHERE year = 2016\n",
    "GROUP BY indicator_code, indicator_name \n",
    "HAVING num_rows >= 175\n",
    "ORDER BY num_rows DESC \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Set up the query\n",
    "safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\n",
    "code_count_query_job = client.query(code_count_query, job_config=safe_config)\n",
    "\n",
    "# API request - run the query, and return a pandas DataFrame\n",
    "code_count_results = code_count_query_job.to_dataframe()\n",
    "\n",
    "# View top few rows of results\n",
    "print(code_count_results.head())\n",
    "\n",
    "# Check your answer\n",
    "q_2.check()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e23040a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##** GOOD ONE  #* CTE\n",
    "\n",
    "# Your code goes here\n",
    "speeds_query = \"\"\"\n",
    "               WITH RelevantRides AS\n",
    "               (\n",
    "                   SELECT trip_start_timestamp, trip_miles, trip_seconds\n",
    "                   FROM `bigquery-public-data.chicago_taxi_trips.taxi_trips`\n",
    "                   WHERE trip_start_timestamp > '2016-01-01' AND trip_start_timestamp < '2016-04-01' AND trip_seconds > 0 AND trip_miles > 0\n",
    "               )\n",
    "               SELECT EXTRACT(HOUR FROM trip_start_timestamp) AS hour_of_day, COUNT(1) AS num_trips, 3600 * SUM(trip_miles)/SUM(trip_seconds) AS avg_mph  \n",
    "               FROM RelevantRides\n",
    "               GROUP BY hour_of_day\n",
    "               ORDER BY hour_of_day\n",
    "               \"\"\"\n",
    "\n",
    "# Set up the query\n",
    "safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\n",
    "speeds_query_job = client.query(speeds_query, job_config=safe_config) # Your code here\n",
    "\n",
    "# API request - run the query, and return a pandas DataFrame\n",
    "speeds_result = speeds_query_job.to_dataframe() # Your code here\n",
    "\n",
    "# View results\n",
    "print(speeds_result)\n",
    "\n",
    "# Check your answer\n",
    "q_5.check()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8676cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "bigquery_experts_query = \"\"\"\n",
    "SELECT a.owner_user_id AS user_id, COUNT(1) AS number_of_answers\n",
    "FROM `bigquery-public-data.stackoverflow.posts_answers` AS a\n",
    "INNER JOIN `bigquery-public-data.stackoverflow.posts_questions` AS q \n",
    "ON a.parent_id = q.id\n",
    "WHERE q.tags LIKE '%bigquery%'\n",
    "GROUP BY a.owner_user_id \n",
    "\"\"\"\n",
    "\n",
    "# Set up the query\n",
    "safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\n",
    "bigquery_experts_query_job = client.query(bigquery_experts_query, job_config=safe_config) # Your code goes here\n",
    "\n",
    "# API request - run the query, and return a pandas DataFrame\n",
    "bigquery_experts_results = bigquery_experts_query_job.to_dataframe() # Your code goes here\n",
    "\n",
    "# Preview results\n",
    "print(bigquery_experts_results.head())\n",
    "\n",
    "# Check your answer\n",
    "q_5.check() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b28950",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##** IMP: **passing a variable in {} braces**\n",
    "#----------\n",
    "# convert what you've done to a general function a website could call on the backend to get experts on any topic: \n",
    "\n",
    "def expert_finder(topic, client):\n",
    "    '''\n",
    "    Returns a DataFrame with the user IDs who have written Stack Overflow answers on a topic.\n",
    "\n",
    "    Inputs:\n",
    "        topic: A string with the topic of interest\n",
    "        client: A Client object that specifies the connection to the Stack Overflow dataset\n",
    "\n",
    "    Outputs:\n",
    "        results: A DataFrame with columns for user_id and number_of_answers. Follows similar logic to bigquery_experts_results shown above.\n",
    "    '''\n",
    "    my_query = \"\"\"\n",
    "               SELECT a.owner_user_id AS user_id, COUNT(1) AS number_of_answers\n",
    "               FROM `bigquery-public-data.stackoverflow.posts_questions` AS q\n",
    "               INNER JOIN `bigquery-public-data.stackoverflow.posts_answers` AS a\n",
    "                   ON q.id = a.parent_Id\n",
    "               WHERE q.tags like '%{topic}%'   #**\n",
    "               GROUP BY a.owner_user_id\n",
    "               \"\"\"\n",
    "\n",
    "    # Set up the query (a real service would have good error handling for \n",
    "    # queries that scan too much data)\n",
    "    safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)      \n",
    "    my_query_job = client.query(my_query, job_config=safe_config)\n",
    "\n",
    "    # API request - run the query, and return a pandas DataFrame\n",
    "    results = my_query_job.to_dataframe()\n",
    "\n",
    "    return results\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0239bebf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585e2dfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1d6309",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## NOTES: \n",
    "#========\n",
    "\n",
    "#** If you are ever unsure what to put inside the COUNT() function, you can do COUNT(1) to count the rows in each group.\n",
    "\n",
    "#** It also scans less data than if supplied column names (making it faster and using less of your data access quota). \n",
    "\n",
    "#* Note that because it tells SQL how to apply aggregate functions (like COUNT()), it doesn't make sense to \n",
    "    # use GROUP BY without an aggregate function. Similarly, if you have any GROUP BY clause, then all variables must be passed to either a\n",
    "        #* GROUP BY command, or\n",
    "        #* an aggregation function.\n",
    "\n",
    "#** this query won't work, because the author column isn't passed to an aggregate function or a GROUP BY clause:\n",
    "query_bad = \"\"\"\n",
    "            SELECT author, parent, COUNT(id)\n",
    "            FROM `bigquery-public-data.hacker_news.comments`\n",
    "            GROUP BY parent\n",
    "            \"\"\"\n",
    "\n",
    "#** ORDER BY is usually the last clause in your query, and it sorts the results returned by the rest of your query. \n",
    "#*  The ORDER BY clause also works for columns containing text, where the results show up in alphabetical order.\n",
    "\n",
    "#** AS is more powerful when combined with WITH in what's called a \"common table expression\" (CTE). \n",
    "#** A common table expression (or CTE) is a temporary table that you return within your query. \n",
    "    # CTEs are helpful for splitting your queries into readable chunks, and you can write queries against them.\n",
    "    #* CTEs only exist inside the query where you create them, and you can't reference them in later queries.\n",
    "    #* CTE query is always broken into two parts: (1) first, we create the CTE, and then (2) we write a query that uses the CTE.\n",
    "    \n",
    "#* In the JOIN query, ON determines which column in each table to use to combine the tables.     \n",
    "    \n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a622f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea566e50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75c623b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762250e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637f15d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826bef3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
